	/xubo/tools/python/python2.7.14/bin/python /xubo/git/spark/examples/src/main/python/status_api_demo.py
	18/01/21 22:34:05 WARN Utils: Your hostname, hadoop resolves to a loopback address: 127.0.0.1; using 10.229.51.168 instead (on interface eth0)
	18/01/21 22:34:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
	18/01/21 22:34:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
	Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
	Setting default log level to "WARN".
	To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
	18/01/21 22:34:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
	Job 0 status:  RUNNING
	Stage 0: 10 tasks total (1 active, 0 complete)
	Stage 1: 10 tasks total (0 active, 0 complete)
	Job 0 status:  RUNNING
	Stage 0: 10 tasks total (1 active, 0 complete)
	Stage 1: 10 tasks total (0 active, 0 complete)
	Job 0 status:  RUNNING
	Stage 0: 10 tasks total (1 active, 0 complete)
	Stage 1: 10 tasks total (0 active, 0 complete)
	Job 0 status:  RUNNING
	Stage 0: 10 tasks total (9 active, 0 complete)
	Stage 1: 10 tasks total (0 active, 0 complete)
	Job 0 status:  RUNNING
	Stage 0: 10 tasks total (9 active, 0 complete)
	Stage 1: 10 tasks total (0 active, 0 complete)
	Job 0 status:  RUNNING
	Stage 0: 10 tasks total (0 active, 10 complete)
	Stage 1: 10 tasks total (0 active, 0 complete)
	Job 0 status:  RUNNING
	Stage 0: 10 tasks total (0 active, 10 complete)
	Stage 1: 10 tasks total (0 active, 0 complete)
	Job 0 status:  RUNNING
	Stage 0: 10 tasks total (0 active, 10 complete)
	Stage 1: 10 tasks total (9 active, 0 complete)
	Job 0 status:  RUNNING
	Stage 0: 10 tasks total (0 active, 10 complete)
	Stage 1: 10 tasks total (9 active, 0 complete)
	Job results are: [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]
	
	Process finished with exit code 0
